---
title: Neural-Network-Based Detection Methods For Color, Sharpness, And Geometry Artifacts In Stereoscopic And VR180 Videos
permalink: /detection_methods_stereoscopic_VR180
features:
  - "These lines will be seen in the post preview"
  - "Write some key features of the paper here"
  - "Add some numerical parameters like 'More than 200 videos in the dataset'"
---

### S.&#x202F;Lavrushkin, K.&#x202F;Kozhemyakov and D.&#x202F;Vatolin

Contact&nbsp;us: 
* <first-author-email>
* <second-author-email>
* <dmitriy.vatolin@graphics.cs.msu.ru>
* <video@compression.ru>

## Abstract
Shooting video in&nbsp;3D format can introduce stereoscopic arti-facts, potentially causing viewers visual discomfort. In&nbsp;this work, we consider three common stereoscopic artifacts: color mismatch, sharpness mismatch, and geometric distortion. This&nbsp;paper introduces two neural-network-based methods for simul-taneous color-&nbsp;and&nbsp;sharpness-mismatch estimation, as&nbsp;well&nbsp;as&nbsp;for estimating geometric distortions. To&nbsp;train these networks we prepared large datasets based&nbsp;on frames from full-length stereoscopic movies and compared the&nbsp;results with methods that previously served in&nbsp;analyses of&nbsp;full-length stereoscopic movies. We used our proposed methods to&nbsp;analyze 100 videos in&nbsp;VR180 format—a&nbsp;new format for stereoscopic videos in&nbsp;virtual reality (VR). This&nbsp;work presents overall results for these videos along&nbsp;with several examples of&nbsp;detected problems.

<!-- Add Download Full Text button-->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<div>
<button class="download-button" role="button" onclick="location.href = 'https://ieeexplore.ieee.org/document/9376385'"> <!-- Insert link here-->
    <i class="fa fa-download"></i>
    Download Full Text
</button>
<p class="download-button-caption">(PDF, 7 MB)</p>  <!-- Insert correct filesize here-->
</div>

## Key Features
* Feature1
* Feature2
* ....
* Powered by [Subjectify.us](https://www.subjectify.us/). <!-- Don't forget to add links to our other projects -->

<!-- 

Main part of the page

 -->

## Cite&nbsp;us
{% highlight BibTeX %}
@inproceedings{inproceedings,
author = {Sergey, Lavrushkin and Konstantin, Kozhemyakov and Dmitriy, Vatolin},
year = {2020},
month = {12},
pages = {1-8},
title = {Neural-Network-Based Detection Methods For Color, Sharpness, And Geometry Artifacts In Stereoscopic And VR180 Videos},
doi = {10.1109/IC3D51119.2020.9376385}}
{% endhighlight %} 

## Contact us

For questions and propositions, please contact us: <first-author-email>, <second-author-email>, ..., <dmitriy.vatolin@graphics.cs.msu.ru>, and <video@compression.ru>

## See also 
* [Video Quality Measurement Tool 3D](https://videoprocessing.ai/stereo_quality/)
* [Stereoscopic Quality Assessment of 1,000 VR180 Videos Using 8 Metrics](https://library.imaging.org/ei/articles/33/2/art00011)
* [Stereoscopic Dataset from A Video Game: Detecting Converged Axes and Perspective Distortions in S3D Videos](https://ieeexplore.ieee.org/document/9376375)
* [MSU benchmarks](https://videoprocessing.ai/benchmarks/)

## References <!-- Other papers that were mentioned in the main part of the page -->
  
1) “VR180.” available online: <https://arvr.google.com/vr180/>.
 
2) A. Antsiferova and D. Vatolin, “The influence of 3D video artifacts on discomfort of 302 viewers,” in 2017 International Conference on 3D Immersion (IC3D), pp. 1–8, IEEE, 2017.

3) S. Winkler, “Efficient measurement of stereoscopic 3D video content issues,” in Image Quality and System Performance XI, vol. 9016, p. 90160Q, International Societyfor Optics and Photonics, 2014. 
  
4) Q. Dong, T. Zhou, Z. Guo, and J. Xiao, “A stereo camera distortion detecting method for 3DTV video quality assessment,” in 2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, pp. 1–4, IEEE, 2013.
  
5) D. G. Lowe, “Object recognition from local scale-invariant features,” in Proceedings of the Seventh IEEE International Conference on Computer Vision, vol. 2, pp. 1150–1157, IEEE, 1999.
  
6) F. Devernay and S. Pujades, “Focus mismatch detection in stereoscopic content,” in Stereoscopic Displays and Applications XXIII, vol. 8288, p. 82880E, International Society for Optics and Photonics, 2012.
  
7) M. Liu and K. Muller, “Automatic analysis of sharpness mismatch between stereoscopic views for stereo 3D videos,” in 2014 International Conference on 3D Imaging (IC3D), pp. 1–6, IEEE, 2014.
  
8) M. A. Fischler and R. C. Bolles, “Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography,” Communications of the ACM, vol. 24, no. 6, pp. 381–395, 1981.
  
9) E. Brachmann, A. Krull, S. Nowozin, J. Shotton, F. Michel, S. Gumhold, and C. Rother, “DSAC-differentiable RANSAC for camera localization,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6684–6692, 2017.
  
10) E. Brachmann and C. Rother, “Neural-guided RANSAC: learning where to sample model hypotheses,” in Proceedings of the IEEE International Conference on Computer Vision, pp. 4322–4331, 2019.
  
11) K. M. Yi, E. Trulls, Y. Ono, V. Lepetit, M. Salzmann, and P. Fua, “Learning to find good correspondences,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2666–2674, 2018.
  
12) 
  
  
  
  
  
  
  
  
  
